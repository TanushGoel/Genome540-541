{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "seq_len = 50\n",
    "vocab_size = 300\n",
    "def train_tokenizer(sequences):\n",
    "    tokenizer = Tokenizer(BPE())\n",
    "    trainer = BpeTrainer(vocab_size=vocab_size-1, show_progress=False)\n",
    "    tokenizer.train_from_iterator(sequences, trainer)\n",
    "    return tokenizer\n",
    "\n",
    "def byte_pair_encode(sequences, tokenizer):\n",
    "    tokenized = []\n",
    "    for seq in sequences:\n",
    "        ids = np.array(tokenizer.encode(seq).ids[:seq_len]) + 1\n",
    "        padding = np.array([0]*(seq_len - len(ids)))\n",
    "        tokenized.append(np.concatenate([ids, padding], axis=0))\n",
    "    return np.array(tokenized, dtype=\"int32\")\n",
    "\n",
    "classes = 2\n",
    "def onehot_label(seq):\n",
    "    return np.eye(classes)[seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = \"/Users/tgoel/Downloads/Classes/GENOME/GENOME541/hw5/encode-chip/\"\n",
    "\n",
    "ids = np.unique([x.split(\".\")[0] for x in os.listdir(PATH)])\n",
    "\n",
    "paths_by_id = []\n",
    "for i in ids:\n",
    "    paths = [x for x in os.listdir(PATH) if i in x]\n",
    "    paths_by_id.append((sorted(paths, key=lambda x: x.split(\".\")[1:], reverse=True), len(paths)))\n",
    "paths_by_id = sorted(paths_by_id, key=lambda x: x[1], reverse=True)\n",
    "train_paths, test_paths = [x[0] for x in paths_by_id[:-4]], [x[0] for x in paths_by_id[-4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(files):\n",
    "\n",
    "    train = len(files) == 6\n",
    "    sequence_paths = [x for x in files if \"fasta\" in x]\n",
    "    labels_paths = [x for x in files if \"label\" in x]\n",
    "\n",
    "    X_valid, X_train, X_test = [open(os.path.join(PATH, path), \"r\").read().strip().split(\"\\n\")[1::2] for path in sequence_paths]\n",
    "    t = train_tokenizer(X_train)\n",
    "    X_train, X_valid, X_test = [byte_pair_encode(x, t) for x in [X_train, X_valid, X_test]]\n",
    "    \n",
    "    if train:\n",
    "        y_valid, y_train, y_test = [onehot_label(np.array([int(x) for x in open(os.path.join(PATH, path), \"r\").read().strip().split(\"\\n\")])) for path in labels_paths]\n",
    "    else:\n",
    "        y_valid, y_train = [onehot_label(np.array([int(x) for x in open(os.path.join(PATH, path), \"r\").read().strip().split(\"\\n\")])) for path in labels_paths]\n",
    "\n",
    "    return (X_train, y_train, X_valid, y_valid, X_test, y_test) if train else (X_train, y_train, X_valid, y_valid, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\")\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(embed_dim)\n",
    "        self.key_dense = tf.keras.layers.Dense(embed_dim)\n",
    "        self.value_dense = tf.keras.layers.Dense(embed_dim)\n",
    "        self.combine_heads = tf.keras.layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'projection_dim': self.projection_dim,\n",
    "            'query_dense': self.query_dense,\n",
    "            'key_dense': self.key_dense,\n",
    "            'value_dense': self.value_dense,\n",
    "            'combine_heads': self.combine_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'att': self.att,\n",
    "            'ffn': self.ffn,\n",
    "            'layernorm1': self.layernorm1,\n",
    "            'layernorm2': self.layernorm2,\n",
    "            'dropout1': self.dropout1,\n",
    "            'dropout2': self.dropout2,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'token_emb': self.token_emb,\n",
    "            'pos_emb': self.pos_emb,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def transformer_model(embed_dim=16, n_heads=4):\n",
    "    tf.keras.backend.clear_session()\n",
    "    inp = tf.keras.layers.Input(shape=(seq_len,))\n",
    "    x = TokenAndPositionEmbedding(seq_len, vocab_size, embed_dim)(inp)\n",
    "    x = TransformerBlock(embed_dim, n_heads, 256)(x)\n",
    "    x = TransformerBlock(embed_dim, n_heads, 512)(x)\n",
    "    x = TransformerBlock(embed_dim, n_heads, 256)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(256, activation=tf.keras.activations.swish)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=tf.keras.activations.swish)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(32, activation=tf.keras.activations.swish)(x)\n",
    "    out = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model for TF 1\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 8s 22ms/step - loss: 0.7029 - accuracy: 0.5000 - auc: 0.5002 - val_loss: 0.6985 - val_accuracy: 0.5000 - val_auc: 0.5208\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 0.6951 - accuracy: 0.5097 - auc: 0.5076 - val_loss: 0.6845 - val_accuracy: 0.6089 - val_auc: 0.6486\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 0.6676 - accuracy: 0.5882 - auc: 0.6272 - val_loss: 0.6748 - val_accuracy: 0.6096 - val_auc: 0.6697\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 0.6216 - accuracy: 0.6547 - auc: 0.7127 - val_loss: 0.6458 - val_accuracy: 0.6532 - val_auc: 0.6906\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 0.5917 - accuracy: 0.6897 - auc: 0.7511 - val_loss: 0.6442 - val_accuracy: 0.6532 - val_auc: 0.7013\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 0.5686 - accuracy: 0.7033 - auc: 0.7758 - val_loss: 0.6372 - val_accuracy: 0.6407 - val_auc: 0.6954\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 0.5510 - accuracy: 0.7180 - auc: 0.7924 - val_loss: 0.6350 - val_accuracy: 0.6454 - val_auc: 0.6978\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 0.5403 - accuracy: 0.7283 - auc: 0.8026 - val_loss: 0.6994 - val_accuracy: 0.5692 - val_auc: 0.6320\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 0.5334 - accuracy: 0.7361 - auc: 0.8092 - val_loss: 0.6893 - val_accuracy: 0.6198 - val_auc: 0.6787\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 0.5041 - accuracy: 0.7493 - auc: 0.8315 - val_loss: 0.7430 - val_accuracy: 0.5871 - val_auc: 0.6367\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6269 - accuracy: 0.6496 - auc: 0.7090\n",
      "\n",
      "Training Model for TF 2\n",
      "Epoch 1/10\n",
      "199/199 [==============================] - 9s 21ms/step - loss: 0.6419 - accuracy: 0.6058 - auc: 0.6677 - val_loss: 0.6317 - val_accuracy: 0.6912 - val_auc: 0.7447\n",
      "Epoch 2/10\n",
      "199/199 [==============================] - 4s 18ms/step - loss: 0.4551 - accuracy: 0.7881 - auc: 0.8677 - val_loss: 0.5160 - val_accuracy: 0.7503 - val_auc: 0.8331\n",
      "Epoch 3/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.4077 - accuracy: 0.8068 - auc: 0.8953 - val_loss: 0.5875 - val_accuracy: 0.7428 - val_auc: 0.8253\n",
      "Epoch 4/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.3909 - accuracy: 0.8224 - auc: 0.9052 - val_loss: 0.4951 - val_accuracy: 0.7629 - val_auc: 0.8489\n",
      "Epoch 5/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.3761 - accuracy: 0.8332 - auc: 0.9126 - val_loss: 0.7022 - val_accuracy: 0.7453 - val_auc: 0.8071\n",
      "Epoch 6/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.3529 - accuracy: 0.8414 - auc: 0.9228 - val_loss: 0.5244 - val_accuracy: 0.7572 - val_auc: 0.8391\n",
      "Epoch 7/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.3312 - accuracy: 0.8544 - auc: 0.9327 - val_loss: 0.6080 - val_accuracy: 0.7390 - val_auc: 0.8205\n",
      "Epoch 8/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.3062 - accuracy: 0.8710 - auc: 0.9427 - val_loss: 0.5752 - val_accuracy: 0.7591 - val_auc: 0.8413\n",
      "Epoch 9/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.2842 - accuracy: 0.8796 - auc: 0.9508 - val_loss: 0.5688 - val_accuracy: 0.7541 - val_auc: 0.8367\n",
      "Epoch 10/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.2552 - accuracy: 0.8931 - auc: 0.9602 - val_loss: 0.6871 - val_accuracy: 0.7371 - val_auc: 0.8249\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8073 - auc: 0.8956\n",
      "\n",
      "Training Model for TF 3\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 8s 21ms/step - loss: 0.6893 - accuracy: 0.5518 - auc: 0.5799 - val_loss: 0.6169 - val_accuracy: 0.6649 - val_auc: 0.7198\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 0.5835 - accuracy: 0.6907 - auc: 0.7589 - val_loss: 0.5787 - val_accuracy: 0.6975 - val_auc: 0.7641\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.5388 - accuracy: 0.7344 - auc: 0.8070 - val_loss: 0.6116 - val_accuracy: 0.6838 - val_auc: 0.7561\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.5118 - accuracy: 0.7552 - auc: 0.8274 - val_loss: 0.6157 - val_accuracy: 0.6767 - val_auc: 0.7457\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.4860 - accuracy: 0.7691 - auc: 0.8466 - val_loss: 0.6187 - val_accuracy: 0.6773 - val_auc: 0.7489\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.4604 - accuracy: 0.7827 - auc: 0.8644 - val_loss: 0.6183 - val_accuracy: 0.6760 - val_auc: 0.7483\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.4339 - accuracy: 0.7992 - auc: 0.8801 - val_loss: 0.7296 - val_accuracy: 0.6812 - val_auc: 0.7488\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.3903 - accuracy: 0.8244 - auc: 0.9049 - val_loss: 0.7658 - val_accuracy: 0.6486 - val_auc: 0.7096\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.3319 - accuracy: 0.8531 - auc: 0.9322 - val_loss: 0.7564 - val_accuracy: 0.6675 - val_auc: 0.7361\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.2625 - accuracy: 0.8920 - auc: 0.9580 - val_loss: 0.8202 - val_accuracy: 0.6525 - val_auc: 0.7149\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5574 - accuracy: 0.7196 - auc: 0.7898\n",
      "\n",
      "Training Model for TF 4\n",
      "Epoch 1/10\n",
      "196/196 [==============================] - 9s 21ms/step - loss: 0.6663 - accuracy: 0.5791 - auc: 0.6277 - val_loss: 0.5681 - val_accuracy: 0.7180 - val_auc: 0.7976\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 3s 18ms/step - loss: 0.5079 - accuracy: 0.7571 - auc: 0.8332 - val_loss: 0.5243 - val_accuracy: 0.7366 - val_auc: 0.8167\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 0.4528 - accuracy: 0.7969 - auc: 0.8698 - val_loss: 0.5390 - val_accuracy: 0.7353 - val_auc: 0.8160\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 0.3991 - accuracy: 0.8198 - auc: 0.9000 - val_loss: 0.5930 - val_accuracy: 0.7110 - val_auc: 0.7974\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 0.3829 - accuracy: 0.8308 - auc: 0.9088 - val_loss: 0.6295 - val_accuracy: 0.7097 - val_auc: 0.7879\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 0.3347 - accuracy: 0.8551 - auc: 0.9312 - val_loss: 0.5693 - val_accuracy: 0.7391 - val_auc: 0.8117\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 0.2727 - accuracy: 0.8833 - auc: 0.9546 - val_loss: 0.6947 - val_accuracy: 0.7180 - val_auc: 0.8035\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 0.2037 - accuracy: 0.9174 - auc: 0.9748 - val_loss: 0.7148 - val_accuracy: 0.7199 - val_auc: 0.7911\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 0.1477 - accuracy: 0.9430 - auc: 0.9863 - val_loss: 0.8052 - val_accuracy: 0.7315 - val_auc: 0.8002\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 0.1106 - accuracy: 0.9581 - auc: 0.9918 - val_loss: 1.0763 - val_accuracy: 0.7027 - val_auc: 0.7672\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.7830 - auc: 0.8531\n",
      "\n",
      "Training Model for TF 5\n",
      "Epoch 1/10\n",
      "140/140 [==============================] - 7s 23ms/step - loss: 0.7087 - accuracy: 0.5015 - auc: 0.5050 - val_loss: 0.6939 - val_accuracy: 0.4996 - val_auc: 0.5010\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6952 - accuracy: 0.5108 - auc: 0.5127 - val_loss: 0.6996 - val_accuracy: 0.5004 - val_auc: 0.4993\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6961 - accuracy: 0.4970 - auc: 0.4951 - val_loss: 0.6932 - val_accuracy: 0.4996 - val_auc: 0.5035\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6946 - accuracy: 0.4889 - auc: 0.4837 - val_loss: 0.6932 - val_accuracy: 0.5004 - val_auc: 0.5004\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6943 - accuracy: 0.4896 - auc: 0.4846 - val_loss: 0.6932 - val_accuracy: 0.5004 - val_auc: 0.5009\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6939 - accuracy: 0.4956 - auc: 0.5008 - val_loss: 0.6933 - val_accuracy: 0.4996 - val_auc: 0.5009\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6934 - accuracy: 0.5006 - auc: 0.5043 - val_loss: 0.6932 - val_accuracy: 0.4996 - val_auc: 0.4996\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6936 - accuracy: 0.4941 - auc: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.4996 - val_auc: 0.4996\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6935 - accuracy: 0.5012 - auc: 0.4951 - val_loss: 0.6932 - val_accuracy: 0.4996 - val_auc: 0.4996\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.6937 - accuracy: 0.4945 - auc: 0.4954 - val_loss: 0.6931 - val_accuracy: 0.5004 - val_auc: 0.5000\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000 - auc: 0.5000\n",
      "\n",
      "Training Model for TF 6\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 8s 22ms/step - loss: 0.6951 - accuracy: 0.5519 - auc: 0.5765 - val_loss: 0.6521 - val_accuracy: 0.6631 - val_auc: 0.7044\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.5728 - accuracy: 0.7040 - auc: 0.7708 - val_loss: 0.5889 - val_accuracy: 0.6864 - val_auc: 0.7543\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.5376 - accuracy: 0.7389 - auc: 0.8049 - val_loss: 0.6597 - val_accuracy: 0.6780 - val_auc: 0.7229\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 3s 18ms/step - loss: 0.5055 - accuracy: 0.7595 - auc: 0.8320 - val_loss: 0.6180 - val_accuracy: 0.6688 - val_auc: 0.7474\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.4886 - accuracy: 0.7754 - auc: 0.8438 - val_loss: 0.6241 - val_accuracy: 0.6935 - val_auc: 0.7574\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.4719 - accuracy: 0.7830 - auc: 0.8555 - val_loss: 0.6646 - val_accuracy: 0.6547 - val_auc: 0.7375\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.4452 - accuracy: 0.8005 - auc: 0.8720 - val_loss: 0.6638 - val_accuracy: 0.6603 - val_auc: 0.7424\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.4198 - accuracy: 0.8146 - auc: 0.8876 - val_loss: 0.7271 - val_accuracy: 0.6455 - val_auc: 0.7133\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.3879 - accuracy: 0.8312 - auc: 0.9045 - val_loss: 0.7220 - val_accuracy: 0.6660 - val_auc: 0.7218\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.3576 - accuracy: 0.8484 - auc: 0.9197 - val_loss: 0.7575 - val_accuracy: 0.6709 - val_auc: 0.7320\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.5592 - accuracy: 0.7055 - auc: 0.7852\n",
      "\n",
      "Training Model for TF 7\n",
      "Epoch 1/10\n",
      "199/199 [==============================] - 9s 21ms/step - loss: 0.7105 - accuracy: 0.5159 - auc: 0.5213 - val_loss: 0.6580 - val_accuracy: 0.6040 - val_auc: 0.6491\n",
      "Epoch 2/10\n",
      "199/199 [==============================] - 4s 19ms/step - loss: 0.5910 - accuracy: 0.6817 - auc: 0.7506 - val_loss: 0.5469 - val_accuracy: 0.7119 - val_auc: 0.7964\n",
      "Epoch 3/10\n",
      "199/199 [==============================] - 3s 18ms/step - loss: 0.4904 - accuracy: 0.7664 - auc: 0.8449 - val_loss: 0.5222 - val_accuracy: 0.7333 - val_auc: 0.8166\n",
      "Epoch 4/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.4600 - accuracy: 0.7880 - auc: 0.8652 - val_loss: 0.5776 - val_accuracy: 0.7339 - val_auc: 0.8040\n",
      "Epoch 5/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.4375 - accuracy: 0.7908 - auc: 0.8787 - val_loss: 0.5308 - val_accuracy: 0.7371 - val_auc: 0.8196\n",
      "Epoch 6/10\n",
      "199/199 [==============================] - 4s 18ms/step - loss: 0.4091 - accuracy: 0.8126 - auc: 0.8954 - val_loss: 0.5428 - val_accuracy: 0.7257 - val_auc: 0.8127\n",
      "Epoch 7/10\n",
      "199/199 [==============================] - 5s 27ms/step - loss: 0.3729 - accuracy: 0.8335 - auc: 0.9140 - val_loss: 0.5753 - val_accuracy: 0.7144 - val_auc: 0.8035\n",
      "Epoch 8/10\n",
      "199/199 [==============================] - 4s 18ms/step - loss: 0.3244 - accuracy: 0.8610 - auc: 0.9356 - val_loss: 0.6197 - val_accuracy: 0.7037 - val_auc: 0.7946\n",
      "Epoch 9/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.2634 - accuracy: 0.8930 - auc: 0.9575 - val_loss: 0.7237 - val_accuracy: 0.7156 - val_auc: 0.7962\n",
      "Epoch 10/10\n",
      "199/199 [==============================] - 3s 17ms/step - loss: 0.1983 - accuracy: 0.9221 - auc: 0.9756 - val_loss: 0.8747 - val_accuracy: 0.7062 - val_auc: 0.7616\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.4825 - accuracy: 0.7705 - auc: 0.8493\n",
      "\n",
      "Training Model for TF 8\n",
      "Epoch 1/10\n",
      "174/174 [==============================] - 8s 22ms/step - loss: 0.7064 - accuracy: 0.5049 - auc: 0.5012 - val_loss: 0.6957 - val_accuracy: 0.5000 - val_auc: 0.5159\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 3s 17ms/step - loss: 0.6953 - accuracy: 0.5138 - auc: 0.5169 - val_loss: 0.6906 - val_accuracy: 0.5058 - val_auc: 0.5607\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 3s 17ms/step - loss: 0.6552 - accuracy: 0.6166 - auc: 0.6597 - val_loss: 0.6637 - val_accuracy: 0.6173 - val_auc: 0.6600\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 3s 17ms/step - loss: 0.6107 - accuracy: 0.6724 - auc: 0.7294 - val_loss: 0.6457 - val_accuracy: 0.6245 - val_auc: 0.6837\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 3s 17ms/step - loss: 0.5887 - accuracy: 0.6948 - auc: 0.7558 - val_loss: 0.6518 - val_accuracy: 0.6266 - val_auc: 0.6788\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 3s 17ms/step - loss: 0.5674 - accuracy: 0.7132 - auc: 0.7785 - val_loss: 0.6756 - val_accuracy: 0.6259 - val_auc: 0.6855\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 3s 17ms/step - loss: 0.5597 - accuracy: 0.7238 - auc: 0.7875 - val_loss: 0.6521 - val_accuracy: 0.6360 - val_auc: 0.6813\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 3s 17ms/step - loss: 0.5372 - accuracy: 0.7403 - auc: 0.8075 - val_loss: 0.7148 - val_accuracy: 0.6122 - val_auc: 0.6668\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 3s 18ms/step - loss: 0.5154 - accuracy: 0.7581 - auc: 0.8249 - val_loss: 0.6750 - val_accuracy: 0.6245 - val_auc: 0.6803\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 3s 20ms/step - loss: 0.4891 - accuracy: 0.7716 - auc: 0.8449 - val_loss: 0.7131 - val_accuracy: 0.6122 - val_auc: 0.6641\n",
      "51/51 [==============================] - 1s 17ms/step - loss: 0.6373 - accuracy: 0.6304 - auc: 0.6934\n",
      "\n",
      "Training Model for TF 9\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 10s 23ms/step - loss: 0.6881 - accuracy: 0.5569 - auc: 0.5790 - val_loss: 0.6648 - val_accuracy: 0.6096 - val_auc: 0.6480\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.6364 - accuracy: 0.6429 - auc: 0.6920 - val_loss: 0.6643 - val_accuracy: 0.6069 - val_auc: 0.6557\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.5998 - accuracy: 0.6770 - auc: 0.7401 - val_loss: 0.6637 - val_accuracy: 0.5976 - val_auc: 0.6368\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.5705 - accuracy: 0.7038 - auc: 0.7719 - val_loss: 0.6747 - val_accuracy: 0.5896 - val_auc: 0.6211\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.5508 - accuracy: 0.7237 - auc: 0.7921 - val_loss: 0.7248 - val_accuracy: 0.6029 - val_auc: 0.6371\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.5186 - accuracy: 0.7431 - auc: 0.8202 - val_loss: 0.8244 - val_accuracy: 0.5796 - val_auc: 0.6114\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.4637 - accuracy: 0.7809 - auc: 0.8623 - val_loss: 0.8428 - val_accuracy: 0.5896 - val_auc: 0.6234\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.3892 - accuracy: 0.8179 - auc: 0.9048 - val_loss: 0.9986 - val_accuracy: 0.5769 - val_auc: 0.6112\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.2831 - accuracy: 0.8826 - auc: 0.9510 - val_loss: 1.0457 - val_accuracy: 0.5650 - val_auc: 0.5900\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.1839 - accuracy: 0.9246 - auc: 0.9791 - val_loss: 1.4763 - val_accuracy: 0.5630 - val_auc: 0.5905\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6471 - accuracy: 0.6261 - auc: 0.6699\n",
      "\n",
      "Training Model for TF 10\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 8s 24ms/step - loss: 0.6945 - accuracy: 0.5395 - auc: 0.5533 - val_loss: 0.7060 - val_accuracy: 0.5120 - val_auc: 0.5625\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.6867 - accuracy: 0.5406 - auc: 0.5697 - val_loss: 0.6628 - val_accuracy: 0.6050 - val_auc: 0.6548\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.6506 - accuracy: 0.6240 - auc: 0.6632 - val_loss: 0.6567 - val_accuracy: 0.6050 - val_auc: 0.6598\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.6294 - accuracy: 0.6446 - auc: 0.6963 - val_loss: 0.6447 - val_accuracy: 0.6165 - val_auc: 0.6651\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.6188 - accuracy: 0.6630 - auc: 0.7104 - val_loss: 0.6481 - val_accuracy: 0.6218 - val_auc: 0.6737\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.6087 - accuracy: 0.6628 - auc: 0.7215 - val_loss: 0.6703 - val_accuracy: 0.6306 - val_auc: 0.6629\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.5825 - accuracy: 0.6884 - auc: 0.7555 - val_loss: 0.6455 - val_accuracy: 0.6147 - val_auc: 0.6737\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.5652 - accuracy: 0.7035 - auc: 0.7710 - val_loss: 0.7117 - val_accuracy: 0.6156 - val_auc: 0.6628\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.5337 - accuracy: 0.7274 - auc: 0.7990 - val_loss: 0.7124 - val_accuracy: 0.6244 - val_auc: 0.6632\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.5040 - accuracy: 0.7464 - auc: 0.8263 - val_loss: 0.7430 - val_accuracy: 0.6058 - val_auc: 0.6512\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6396 - accuracy: 0.6493 - auc: 0.6940\n"
     ]
    }
   ],
   "source": [
    "for transcription_factor in range(len(train_paths)):\n",
    "    print(\"\\nTraining Model for TF\", str(transcription_factor+1))\n",
    "    model = transformer_model()\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"/Users/tgoel/Downloads/Classes/GENOME/GENOME541/hw5/models/model_\" + str(transcription_factor+1) + \".yaml\", monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = get_data(train_paths[transcription_factor])\n",
    "\n",
    "    hist = model.fit(X_train, y_train, epochs=10, batch_size=32, shuffle=True,\n",
    "                     validation_data=[X_valid, y_valid], callbacks=[checkpoint])\n",
    "    \n",
    "    model.load_weights(\"/Users/tgoel/Downloads/Classes/GENOME/GENOME541/hw5/models/model_\" + str(transcription_factor+1) + \".yaml\")\n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "209/209 [==============================] - 9s 20ms/step - loss: 0.7069 - accuracy: 0.5117 - auc: 0.5131 - val_loss: 0.6780 - val_accuracy: 0.6088 - val_auc: 0.6603\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 3s 17ms/step - loss: 0.5477 - accuracy: 0.7207 - auc: 0.7970 - val_loss: 0.5201 - val_accuracy: 0.7837 - val_auc: 0.8508\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 3s 17ms/step - loss: 0.4060 - accuracy: 0.8201 - auc: 0.8975 - val_loss: 0.4446 - val_accuracy: 0.8029 - val_auc: 0.8804\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - 3s 16ms/step - loss: 0.3702 - accuracy: 0.8350 - auc: 0.9154 - val_loss: 0.4539 - val_accuracy: 0.7825 - val_auc: 0.8713\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 3s 16ms/step - loss: 0.3512 - accuracy: 0.8474 - auc: 0.9241 - val_loss: 0.4493 - val_accuracy: 0.8053 - val_auc: 0.8769\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - 3s 16ms/step - loss: 0.3158 - accuracy: 0.8641 - auc: 0.9388 - val_loss: 0.4931 - val_accuracy: 0.8023 - val_auc: 0.8692\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 3s 16ms/step - loss: 0.2853 - accuracy: 0.8730 - auc: 0.9502 - val_loss: 0.4967 - val_accuracy: 0.8005 - val_auc: 0.8834\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - 3s 16ms/step - loss: 0.2494 - accuracy: 0.8953 - auc: 0.9620 - val_loss: 0.4667 - val_accuracy: 0.7969 - val_auc: 0.8743\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 3s 16ms/step - loss: 0.2140 - accuracy: 0.9141 - auc: 0.9721 - val_loss: 0.5139 - val_accuracy: 0.7975 - val_auc: 0.8823\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - 3s 16ms/step - loss: 0.1762 - accuracy: 0.9273 - auc: 0.9810 - val_loss: 0.6412 - val_accuracy: 0.7999 - val_auc: 0.8797\n",
      "52/52 [==============================] - 1s 7ms/step\n",
      "Epoch 1/10\n",
      "204/204 [==============================] - 9s 21ms/step - loss: 0.6187 - accuracy: 0.6512 - auc: 0.7151 - val_loss: 0.5112 - val_accuracy: 0.7494 - val_auc: 0.8294\n",
      "Epoch 2/10\n",
      "204/204 [==============================] - 3s 17ms/step - loss: 0.4704 - accuracy: 0.7779 - auc: 0.8579 - val_loss: 0.5026 - val_accuracy: 0.7555 - val_auc: 0.8339\n",
      "Epoch 3/10\n",
      "204/204 [==============================] - 4s 17ms/step - loss: 0.4276 - accuracy: 0.8034 - auc: 0.8849 - val_loss: 0.4481 - val_accuracy: 0.7973 - val_auc: 0.8744\n",
      "Epoch 4/10\n",
      "204/204 [==============================] - 3s 17ms/step - loss: 0.3779 - accuracy: 0.8287 - auc: 0.9111 - val_loss: 0.5158 - val_accuracy: 0.7832 - val_auc: 0.8562\n",
      "Epoch 5/10\n",
      "204/204 [==============================] - 3s 17ms/step - loss: 0.3366 - accuracy: 0.8544 - auc: 0.9302 - val_loss: 0.4721 - val_accuracy: 0.7912 - val_auc: 0.8704\n",
      "Epoch 6/10\n",
      "204/204 [==============================] - 4s 18ms/step - loss: 0.2672 - accuracy: 0.8858 - auc: 0.9565 - val_loss: 0.5736 - val_accuracy: 0.7611 - val_auc: 0.8315\n",
      "Epoch 7/10\n",
      "204/204 [==============================] - 4s 17ms/step - loss: 0.1988 - accuracy: 0.9205 - auc: 0.9759 - val_loss: 0.7968 - val_accuracy: 0.7746 - val_auc: 0.8361\n",
      "Epoch 8/10\n",
      "204/204 [==============================] - 4s 17ms/step - loss: 0.1508 - accuracy: 0.9417 - auc: 0.9856 - val_loss: 0.7291 - val_accuracy: 0.7531 - val_auc: 0.8287\n",
      "Epoch 9/10\n",
      "204/204 [==============================] - 3s 17ms/step - loss: 0.0967 - accuracy: 0.9627 - auc: 0.9939 - val_loss: 0.8222 - val_accuracy: 0.7758 - val_auc: 0.8518\n",
      "Epoch 10/10\n",
      "204/204 [==============================] - 3s 17ms/step - loss: 0.0710 - accuracy: 0.9738 - auc: 0.9963 - val_loss: 0.9318 - val_accuracy: 0.7678 - val_auc: 0.8400\n",
      "58/58 [==============================] - 1s 7ms/step\n",
      "Epoch 1/10\n",
      "194/194 [==============================] - 9s 23ms/step - loss: 0.6977 - accuracy: 0.5181 - auc: 0.5252 - val_loss: 0.6703 - val_accuracy: 0.5935 - val_auc: 0.6381\n",
      "Epoch 2/10\n",
      "194/194 [==============================] - 3s 17ms/step - loss: 0.6142 - accuracy: 0.6670 - auc: 0.7197 - val_loss: 0.6198 - val_accuracy: 0.6665 - val_auc: 0.7271\n",
      "Epoch 3/10\n",
      "194/194 [==============================] - 3s 17ms/step - loss: 0.5602 - accuracy: 0.7178 - auc: 0.7822 - val_loss: 0.5666 - val_accuracy: 0.7039 - val_auc: 0.7825\n",
      "Epoch 4/10\n",
      "194/194 [==============================] - 3s 17ms/step - loss: 0.5218 - accuracy: 0.7423 - auc: 0.8169 - val_loss: 0.5550 - val_accuracy: 0.7019 - val_auc: 0.7843\n",
      "Epoch 5/10\n",
      "194/194 [==============================] - 3s 17ms/step - loss: 0.5126 - accuracy: 0.7438 - auc: 0.8243 - val_loss: 0.5773 - val_accuracy: 0.6806 - val_auc: 0.7634\n",
      "Epoch 6/10\n",
      "194/194 [==============================] - 3s 17ms/step - loss: 0.4811 - accuracy: 0.7675 - auc: 0.8481 - val_loss: 0.5930 - val_accuracy: 0.6935 - val_auc: 0.7646\n",
      "Epoch 7/10\n",
      "194/194 [==============================] - 3s 17ms/step - loss: 0.4577 - accuracy: 0.7814 - auc: 0.8645 - val_loss: 0.5791 - val_accuracy: 0.7090 - val_auc: 0.7836\n",
      "Epoch 8/10\n",
      "194/194 [==============================] - 3s 17ms/step - loss: 0.4203 - accuracy: 0.8062 - auc: 0.8883 - val_loss: 0.6616 - val_accuracy: 0.7000 - val_auc: 0.7722\n",
      "Epoch 9/10\n",
      "194/194 [==============================] - 3s 17ms/step - loss: 0.3816 - accuracy: 0.8315 - auc: 0.9096 - val_loss: 0.6775 - val_accuracy: 0.6994 - val_auc: 0.7659\n",
      "Epoch 10/10\n",
      "194/194 [==============================] - 3s 17ms/step - loss: 0.3228 - accuracy: 0.8623 - auc: 0.9361 - val_loss: 0.7007 - val_accuracy: 0.6974 - val_auc: 0.7731\n",
      "59/59 [==============================] - 1s 7ms/step\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 9s 23ms/step - loss: 0.6784 - accuracy: 0.5786 - auc: 0.6120 - val_loss: 0.7390 - val_accuracy: 0.7204 - val_auc: 0.7687\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 3s 18ms/step - loss: 0.3915 - accuracy: 0.8320 - auc: 0.9058 - val_loss: 0.4510 - val_accuracy: 0.8121 - val_auc: 0.8743\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 3s 18ms/step - loss: 0.2999 - accuracy: 0.8793 - auc: 0.9444 - val_loss: 0.4481 - val_accuracy: 0.8166 - val_auc: 0.8760\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 3s 17ms/step - loss: 0.2743 - accuracy: 0.8874 - auc: 0.9535 - val_loss: 0.4695 - val_accuracy: 0.8212 - val_auc: 0.8851\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 3s 17ms/step - loss: 0.2494 - accuracy: 0.9009 - auc: 0.9617 - val_loss: 0.4684 - val_accuracy: 0.8121 - val_auc: 0.8804\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 3s 18ms/step - loss: 0.2316 - accuracy: 0.9118 - auc: 0.9668 - val_loss: 0.5113 - val_accuracy: 0.7991 - val_auc: 0.8715\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 3s 17ms/step - loss: 0.2135 - accuracy: 0.9191 - auc: 0.9712 - val_loss: 0.5383 - val_accuracy: 0.7945 - val_auc: 0.8629\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 3s 17ms/step - loss: 0.2024 - accuracy: 0.9204 - auc: 0.9744 - val_loss: 0.6386 - val_accuracy: 0.7841 - val_auc: 0.8584\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 3s 18ms/step - loss: 0.1688 - accuracy: 0.9350 - auc: 0.9818 - val_loss: 0.6678 - val_accuracy: 0.7757 - val_auc: 0.8562\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 3s 18ms/step - loss: 0.1533 - accuracy: 0.9446 - auc: 0.9847 - val_loss: 0.6885 - val_accuracy: 0.7562 - val_auc: 0.8436\n",
      "62/62 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "for transcription_factor in range(len(train_paths), len(train_paths) + len(test_paths)):\n",
    "    print(\"\\nTraining Model for TF\", str(transcription_factor+1))\n",
    "    model = transformer_model()\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"/Users/tgoel/Downloads/Classes/GENOME/GENOME541/hw5/models/model_\" + str(transcription_factor+1) + \".yaml\", monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\n",
    "    X_train, y_train, X_valid, y_valid, X_test = get_data(test_paths[transcription_factor-len(train_paths)])\n",
    "\n",
    "    hist = model.fit(X_train, y_train, epochs=10, batch_size=32, shuffle=True,\n",
    "                     validation_data=[X_valid, y_valid], callbacks=[checkpoint])\n",
    "    \n",
    "    model.load_weights(\"/Users/tgoel/Downloads/Classes/GENOME/GENOME541/hw5/models/model_\" + str(transcription_factor+1) + \".yaml\")\n",
    "    y_preds.append(model.predict(X_test)[::,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "for transcription_factor, y_pred in enumerate(y_preds):\n",
    "    with open(\"/Users/tgoel/Downloads/Classes/GENOME/GENOME541/hw5/predictions_\" + str(transcription_factor+1) + \".pkl\", \"wb\") as f:\n",
    "        pkl.dump(y_pred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
